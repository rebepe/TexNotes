absolute Häufigkeit: $h_i$

relative Häufigkeit: $f_i= \frac{h_i}{n}$

kumulative Häufigkeitsverteilung: H(x) =$\sum_{i:a_i < x} h_i$

empirische Verteilfunktion: $F(x) =  \frac{1}{n} H(x) = \sum_{i:a_i < x} f_i$

arithmetisches Mittel: $\overline{x} = \frac{1}{n} \sum_{i=1}^n x_i = \frac{1}{n} \sum_{i=1}^n h_i a_i $

geometrisches Mittel $\overline{x}_{geom} = \sqrt[n]{\prod_{i=1}^n x_i}$

$\overline{x}_{geom} \leq \overline{x}$

median:  $\tilde{x} = \frac{1}{2} (\lfloor \frac{n}{2} \rfloor + \lceil \frac{n}{2} \rceil )  $ // 50\% größer bzw. kleiner


Modus = häufigster Wert

empirische Varianz: $s^2  = \frac{1}{n-1}\left(\sum_{i=1}^n x_i^2-n\overline{x}^2\right)= \gray{\frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})^2}$

Standardabweichung:  $s = \sqrt{varianz} $

Kovarianz: $s_{xy} = \frac{1}{n-1}\sum_{i=1}^n(x_i-\overline{x})(y_i-\overline{y})$

Korrelationskoeffizient: $r_{xy} = \frac{s_{xy}}{s_x\cdot s_y}$

\section*{Bedingte Wahrscheinlichkeiten}

prob(A) = $\frac{\text{|günstige Fälle|}}{\text{| alle Fälle|}}$

$prob(B|A) = \frac{prob(B \cap A)}{prob(A)}$

Unabhängig $\Leftrightarrow prob(A \cap B)=prob(A)\cdot prob(B)$

Satz von Bayes: $prob(B|A) = prob(A|B)\dfrac{prob(B)}{prob(A)}$

$prob(B|A) = \dfrac{prob(A|B)\cdot prob(B)}{prob(B)\cdot prob(A|B) + prob(\overline{B}) \cdot prob(A|\overline{B}) }$


\section*{Erwartungswert}
diskret: $ E(X) = \sum_i^n prob(x_i)\cdot x_i$\\
stetig: $E(X) = \int_{-\infty}^{\infty}xf(x)dx$\\

E(X+Y) = E(X) + E(Y);~~~ E(aX) = aE(X) \\
wenn f symmetrisch um c dann E(X) = c\\
wenn X,Y unabhängig: E(XY) = E(X) $\cdot$ E(Y)

\section*{Kovarianz}
$Cov(X,Y) = E(X \cdot Y) -E(X)E(Y)= \gray{E((X-E(X))\cdot(Y-E(Y)) }$

\section*{varianz}
diskret: $ \sigma^2 = \sum_i^n prob(x_i)\cdot (x_i -E(X))^2$\\
stetig: $ \sigma^2 = \int_{-\infty}^{\infty} (x -E(X))^2 f(x) dx$ \\
$\sigma^2 = E(X^2) - E(X)^2$

Var(X+Y) = Var(X) + Var(Y) \gray{ + 2Cov(X,Y)}\\
Var(aX+b) = $a^2$Var(X)


\section*{Standardisierung}
standartisierte Zufallsvariable $Z:=\dfrac{X-\mu}{\sigma}$ => E(X)=0, Var(X)=1


\section*{Verteilungsfunktionen}
Verteilungsfunktion F(x) $= prob(X \leq x)$\\
steigt monoton von 0 nach 1

Dichte: f(x);

$f(x) = F'(x); \\
 F(x) = \int_{-\infty}^xf(x)dx$

Bsp: 

$f(x) = \begin{cases}
\textcolor{red}{ax}   &  \textcolor{blue}{-2} < x \leq \textcolor{blue}{1} \\ 
\textcolor{green}{ax^2} & 1<x\leq \textcolor{blue}{5}\\ 
\textcolor{lightgray}{0}  & sonst
\end{cases}$

\begin{align*}
\int_{-\infty}^x \textcolor{lightgray}{0} dx & = 0;  &=> F(\textcolor{blue}{-2}) = 0
\\
0 + \int_{-2}^x \textcolor{red}{ax} dx & = \frac{1}{2}ax^2 |_{-2}^x = \frac{1}{2}ax^2 +2a &=> F(\textcolor{blue}{1}) = \textcolor{magenta}{2,5a} 
\\
\textcolor{magenta}{2,5a} + \int_{1}^x \textcolor{green}{ax^2} dx &= \frac{1}{3}ax^3 |_{1}^x +2,5a =  \frac{1}{3}ax^3 + \frac{1}{3} a  +2,5a &=> F(\textcolor{blue}{5}) = \textcolor{orange}{44,5 a}
\\ 
\textcolor{orange}{44,5 a} + \int_5^x \textcolor{lightgray}{0} dx &= 44,5a
\end{align*}
$ \Rightarrow 44,5a = 1 \dots$ 


\newpage

\subsection*{Gleichverteilung}
$f(x) = \frac{1}{b-a} falls a < x < b, sonst 0$

$F(x)  = \frac{x-a}{b-a} falls a < x < b, sonst 0 bzw. 1$

E(X) = (b+a)/2


\subsection*{Hypergeometrische Verteilung}
N Elemente, M Treffermöglichkeiten, Stichprobe mit n (kein Zurücklegen)

prob(X=x)=$ \dfrac{\left( \! \begin{array}{c}M \\ x \end{array} \! \right) \cdot \left( \begin{array}{c}N-M \\ n-x \end{array}  \right) }{\left( \begin{array}{c}N \\ n \end{array}  \right) }$

$E(X)=n\dfrac{M}{N}~~~
Var(X) = n\dfrac{M}{N} \left( 1- \dfrac{M}{N} \right) \dfrac{N-n}{N-1}
$

\Naeherung bei $ 20 n \leq N $  durch Binomialverteilung

\subsection*{binomialverteilung}
Stichprobe mit n, wahrscheinlichkeit pro Teil: p 

$prob(X=x) = \left( \begin{array}{c} n \\ x \end{array} \right) p^x (1-p)^{n-x}$

E(X) = np; ~~~ Var(X) = np(1-p)

\gray{Wenn X = Bi(n;p) und Y = Bi(m;p) unabhängig, dann X + Y = Bi(m+n;p)}

\Naeherung  Bei $n \geq 50, p \leq 0.1 $ durch Poisson-Verteilung mit $\lambda = np$

\Naeherung Bei $np(1-p)\geq 9$: $F_B(x) \approx F_N(x+0.5) = \Phi \left( \dfrac{x+0.5 -np}{\sqrt{np(1-p)}}\right)$


\subsection*{Poisson-Verteilung}
\gray{Auftreten von Ereignis in Zeitinterval:}

$prob(X=x) = \dfrac{\lambda^x}{x!}e^{-\lambda}$

$E(X) = Var(X) = \lambda$

\Naeherung Bei $\lambda \geq 9$ $F_P(x) \approx F_N(x+0.5)=\Phi \left( \dfrac{x+0.5-\lambda}{\sqrt{\lambda}}\right)$


\subsection*{Exponentialverteilung}
$F(x) = 1 - e^{-\lambda x};  \\ f(x) = \lambda e^{-\lambda x}$ für x > 0 \\
E(X) = $1/\lambda$ \gray{= Durchschnittliche Lebensdauer}\\
Var(X) = $1/\lambda^2$

%\subsubsection*{\gray{Weibull-Verteilung}}
%\gray{$F(x) = 1 - e^{\lambda x^\beta};  \\f(x) = \lambda \beta x^{\beta -1} e^{-\lambda x^\beta}$ für x > 0 }

\subsection*{Normalverteilung}
\gray{$f(x) = \frac{1}{\sqrt{2\pi}\sigma} \cdot e^{-0,5\left(\frac{x-\mu}{\sigma}\right)^2}$\\
$\mu = erwartungswert,\sigma^2 = Varianz$\\
$X = N(\mu;\sigma^2), Y = aX + b \Rightarrow Y = N(a\mu + b; a^2\sigma^2)$}

\subsubsection*{Standard-Normalverteilung $z_p$}
\gray{Dichte: $\phi(x) = \frac{1}{\sqrt{2\pi}} \cdot e^{- 0,5 x^2}$\\
Verteilung: $\Phi$ ~~~~~~
$\Phi(-x) = 1-\Phi(x)$\\
E(X) = 0; Var(X) = 1;}


Ablesen an Standard-Normalverteilung: $F(X) = \Phi \left(\dfrac{x-\mu}{\sigma} \right)$, $f(x) = \dfrac{\phi}{\sigma} \left(\dfrac{x-\mu}{\sigma} \right)$

\subsection*{Zentraler Grenzwertsatz, schwache Konvergenz}
Summe über identisch Verteilte Zufallsvariablen $X_i mit E(X_i) = \mu, Var(X_i) = \sigma^2$\\
$X_1 + X_2 + \dots + X_n$\\
Für große n: Normalverteilt mit E = $n\mu$ Var = $n\sigma^2$

\newpage

\section*{Zufallsstichproben}
\gray{n gewählte Elemente, die Werte sind zufällig verteilt; wenn ausgreichend Große Grundgesamtheit: Werte unabhängig und gleich verteilt}

\subsection*{Punktschätzer}
\gray{Test einer Verteilung mit zu schätzendem Parameter $\theta$\\
Eigenschaften:\\
\begin{minipage}{0.5\textwidth}
\begin{enumerate}
\item erwartungstreu falls E(T) = $\theta$;~~~~ bias=$E(T)-\theta$
\item asymptotisch erwartungstreu: $\lim_{n\rightarrow \infty} E(T_n) = \theta$
\item konsistent: konvergiert stochastisch gegen $\theta$ \\
( $\lim_{n\rightarrow \infty} prob (|T_n - \theta| <\epsilon ) = 1$ für alle $\epsilon >0 $
\item konsistent im quadratischen Mittel: $\lim_{n\rightarrow \infty} E((T_n-\theta)^2) = 0$\\
bzw. wenn asymptotisch erwartungstreu und Var(X)$\rightarrow$ 0 \\
=> ist auch konsistent; Bsp: arithmetisches Mittel, empirische Verteilung
\end{enumerate}
\end{minipage}
}
\subsubsection*{Maximum-Likelihood}
\gray{asymptotisch erwartungstreu, asymptotisch normalverteilt mit $\mu = \theta$, Varianz minimal}

\begin{minipage}{0.25\textwidth}
\begin{enumerate}
\item Berechne f(x) wenn nicht gegeben \\(Ableiten von F(x) nach x)
\item $L = \prod_{i=1}^n f(x_i,\theta)$
\item berechne ln(L) 
\item berechne maximum von L \\\textbf{(ABLEITEN nach $\lambda$, = 0 } 
\end{enumerate}
\end{minipage}
\begin{minipage}{0.25\textwidth}
\textcolor{gray}{
\begin{enumerate}
\item Bsp: f(x) = $\lambda e^ {-\lambda x_i}$\\
\item $ L = \prod_{i=1}^n \lambda e^ {-\lambda x_i}$
\item $	z.B. ln(L) = n ln(\lambda) -\lambda \sum_{i=1}^n x_i $
\item $n/\lambda - \sum_{i=1}^n x_i \dots$ \textbf{=0}\\
auflösen $\lambda = n/ \sum_{i=1}^n x_i$
\end{enumerate}}
\end{minipage}

\newcommand{\bc}{\textcolor{orange}{c}}
\newcommand{\red}[1]{\textcolor{red}{#1}}

Logarithmen:
\begin{itemize}
\item $log(\red{xy}) = log(\red{x}) + log(\red{y})$
\item $log(x^{\bc}) = \bc log(x)$
\item $e^{ln(x)} = x$
\end{itemize}

\newpage

\subsubsection*{Least Squares/Regressionsrechnung (Gauß):}
Zu nähernde Funktion f(x) in Parameterform, z.B. Gerade: y= mx+t\\
Stichprobe mit Wertepaaren: $(x_1,y_1)\dots (x_n,y_n)$

\begin{enumerate}
\item Bilde s$\Delta : = \sum_{i=1}^n(y_i - f(x_i))^2$
\item Leite nach jedem Parameter ab, setze gleich Null, bestimme Parameter
\end{enumerate}

Alternative für Geraden: $m= r_{xy}\frac{s_y}{s_x}, t = \overline{y}-m\overline{x}$

\subsection*{Intervallschätzung / Konfidenzinterval}
Irrtumswahrscheinlichkeit: $\alpha$ 
Konfidenzniveau: $1-\alpha$\\

zweiseitiges Konfidenzintervall: Intervall zwischen $\overline{x} \pm Abweichung$ ~~~~ //siehe Folgende
einseitiges Konfidenzintervall: $[-\infty; \overline{x} + Abweichung]$

\textbf{wenn $\sigma$ nicht gegeben }\\
Abweichung(zweiseitig): $\dfrac{s}{\sqrt{n}} \cdot t_{n-1;~ 1-\alpha/2}$\\
Abweichung(einseitig): $\dfrac{s}{\sqrt{n}} \cdot t_{n-1;~ 1-\alpha}$

\textbf{wenn $\sigma$ gegeben}\\
Abweichung(zweiseitig): $\dfrac{\sigma}{\sqrt{n}}\cdot  z_{1-\alpha/2}$\\
Abweichung(einseitig): $\dfrac{\sigma}{\sqrt{n}} \cdot z_{1-\alpha}$


\section*{t-Test}
Test auf Erwartungswert = vermuteter Wert \\
Stichprobe mit Mittelwert $\overline{x}$; Hypothese $H_0: \mu = \mu_0$\\
Prüfwert: $z= \dfrac{\overline{x} - \mu_0}{s/\sqrt{n}}$

\subsection*{zweiseitig}
Ablehnungsbereich: $|z| > t_{n-1;1-\alpha/2} => H_0 $muss verworfen werden 
\subsection*{einseitig}
Ablehnungsbereich: $|z| > t_{n-1;1-\alpha} => H_0 $muss verworfen werden 


\section*{Chi-Quadrat-Anpassungstest}
Test auf Verteilung = vermutete Verteilung\\
Vorraussetzung: große Stichprobe: ($np_i \geq 5$) für alle i

\begin{enumerate}
\item Teile Werte in Intervalle $I_i$ auf; \gray{// Aus angabe entnehmen}
\item $h_i:$ Anzahl der Werte in $I_i$ \gray{// Aus angabe entnehmen} 
\item $p_i$ : Wahrscheinlichkeit von $I_i$ laut vermuteter Verteilung \\
\gray{// Berechne aus Verteilungsfunktion \textcolor{lightgray}{obere Grenze -untere Grenze}}\\

\item $y = \gray{ \sum_{i=1}^k \dfrac{(h_i -np_i)^2}{n p_i} }= 1/n \left( \sum_{i_1}^k \dfrac{h_i^2}{p_i} \right) -n $
\gray{ist asymptotisch  $\chi^2 (k-1)$ verteilt }\\

\item 0 geschätzte Parameter: Ablehnungsbereich: y > $\chi^2_{k-1;1-\alpha}$

g geschätzte Parameter: Ablehnungsbereich: y > $\chi^2_{k-1-g;1-\alpha}$

\end{enumerate}